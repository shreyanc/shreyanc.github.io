---
layout: default
published: true
is_home_page: true
---
## Hi!

I am a PhD student at the [Institute of Computational Perception](https://www.jku.at/en/institute-of-computational-perception/) in Johannes Kepler University Linz, Austria.

I work with deep learning models applied to music audio signals to understand what makes musical performances expressive and how we can make systems that respond appropriately to the subjective and affective qualities of music, perception of which is a uniquely human characteristic.

Currently I am a part of the [Con Espressione](https://www.jku.at/en/institute-of-computational-perception/research/projects/con-espressione/) project, and [Prof. Gerhard Widmer](https://www.jku.at/en/institute-of-computational-perception/about-us/people/gerhard-widmer/) is my supervisor.

<br>

<!--<ul class="downloads">
  <li><a href="#Publications"><strong>Publications</strong></a></li>
  <li><a href="#"><strong>About Me</strong></a></li>
 </ul>
 
<br><br>-->
## Updates
### 2021
----
**September 30, 2021**: Passed my pre-defense colloquium! [[slides]](assets/pdf/Colloquium_2021-09-30.pdf)

**August 19, 2021**: Gave a talk at [MAPLE lab, McMaster University](https://maplelab.net/) titled "Towards Better Features for Music Emotion Recognition: A Machine Learning Approach". [[slides]](assets/pdf/McMasterLabPresentation_2021-08-19_final.pdf)

**June 30, 2021**: Presented our work on two-level explanations with sound sources and mid-level features at SMC 2021. [[paper]](https://arxiv.org/abs/2106.07787)

**June 10, 2021**: Presented our work on domain adaptation of perceptual features in music at ICASSP 2021. [[paper]](https://arxiv.org/abs/2102.13479)

<br>
### 2020
----
**December 12, 2020**: Patent granted for our work on audio analytics that I worked on while at Honeywell (project duration: 2017-18). [[patent]](https://patents.google.com/patent/US10475468B1)

<br>
### 2019
----
**November 5, 2019**: Presented my work on explainable emotion recognition in ISMIR 2019, Delft. [[teaser talk]](https://collegerama.tudelft.nl/Mediasite/Showcase/ismir2019/Presentation/b68bfc2ef9214728ac2d5c3d4d3119061d) [[paper/poster/demo]](https://shreyanc.github.io/ismir2019_paper_poster.html)

**October 27, 2019**: Presented our state-of-the-art results on [emotion and theme recognition task at MediaEval 2019](https://multimediaeval.github.io/2019-Emotion-and-Theme-Recognition-in-Music-Task/) in Sophia Antipolis, France. [[paper]](https://arxiv.org/abs/1911.05833)

**October 16, 2019**: Gave a guest talk at the [Acoustics Research Institute, ÖAW (Austrian Academy of Sciences)](https://www.oeaw.ac.at/isf/home) with [Verena Haunschmid](https://www.jku.at/en/institute-of-computational-perception/about-us/people/verena-haunschmid) on Explainable Models and their Application in Music Emotion Recognition.

<br>

## Publications
### 2021
----
[On Perceived Emotion in Expressive Piano Performance: Further Experimental Evidence for the Relevance of Mid-level Features (2021)](https://arxiv.org/abs/2107.13231)
> **Shreyan Chowdhury**, Gerhard Widmer<br>
> ISMIR 2021, Virtual

[Tracing Back Music Emotion Predictions to Sound Sources and Intuitive Perceptual Qualities (2021)](https://arxiv.org/abs/2106.07787)
> **Shreyan Chowdhury**, Verena Praher, Gerhard Widmer<br>
> Sound and Music Computing Conference 2021

[Towards Explaining Expressive Qualities in Piano Recordings: Transfer of Explanatory Features via Acoustic Domain Adaptation (2021)](https://arxiv.org/abs/2102.13479)
> **Shreyan Chowdhury**, Gerhard Widmer<br>
> ICASSP 2021, Toronto, Canada

<br>

### 2020
----
[The Con Espressione Game Dataset (1.0.0)](https://doi.org/10.5281/zenodo.3968828)
> Carlos Cancino-Chacón, Silvan Peter, **Shreyan Chowdhury**, Anna Aljanaki, Gerhard Widmer<br>
> ISMIR 2019, Montreal, Canada

[On the Characterization of Expressive Performance in Classical Music: First Results of the Con Espressione Game (2020)](https://arxiv.org/abs/2008.02194)
> Carlos Cancino-Chacón, Silvan Peter, **Shreyan Chowdhury**, Anna Aljanaki, Gerhard Widmer<br>
> ISMIR 2019, Montreal, Canada

<br>

### 2019
----

[Emotion and Theme Recognition in Music with Frequency-Aware RF-Regularized CNNs (2019)](https://www.jku.at/fileadmin/gruppen/173/Research/Emotion_in_Music_with_Frequency-Aware_RF-Regularized_CNNs_Koutini.pdf)
> Khaled Koutini, **Shreyan Chowdhury**, Verena Haunschmid, Hamid Eghbal-zadeh, Gerhard Widmer<br>
> MediaEval Multimedia Benchmark 2019, Sophia Antipolis

[Towards Explainable Music Emotion Recognition: The Route via Mid-level Features (2019)](https://arxiv.org/abs/1907.03572) [[demo]](https://shreyanc.github.io/ismir_example.html)
>**Shreyan Chowdhury**, Andreu Vall, Verena Haunschmid, Gerhard Widmer<br>
>ISMIR 2019, Delft, Netherlands

[Two-level Explanations in Music Emotion Recognition (2019)](https://arxiv.org/abs/1905.11760) [[demo]](https://shreyanc.github.io/ICML_example.html)
>Verena Haunschmid, **Shreyan Chowdhury**, Gerhard Widmer<br>
>ICML 2019, Machine Learning for Music Discovery Workshop

<br>

### 2017
----

[Music Tempo Estimation Using Sub-Band Synchrony (2017)](https://www.isca-speech.org/archive/Interspeech_2017/pdfs/1000.PDF) [[poster]](http://tanayag.com/Pub_files/chowdhury_ISposter.pdf)
>**Shreyan Chowdhury**, Tanaya Guha, Rajesh M Hegde<br>
>INTERSPEECH, 3093-3096
